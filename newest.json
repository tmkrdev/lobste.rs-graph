[{"short_id":"oyw4ne","short_id_url":"https://lobste.rs/s/oyw4ne","created_at":"2024-06-24T17:04:49.000-05:00","title":"Pivoting From React to Native DOM APIs: A Real World Example","url":"https://thenewstack.io/pivoting-from-react-to-native-dom-apis-a-real-world-example/","score":1,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/oyw4ne/pivoting_from_react_native_dom_apis_real","submitter_user":"deejayy","user_is_author":false,"tags":["web"]},{"short_id":"4rffe2","short_id_url":"https://lobste.rs/s/4rffe2","created_at":"2024-06-24T15:32:40.000-05:00","title":"More Memory Safety for Let’s Encrypt: Deploying ntpd-rs","url":"https://letsencrypt.org/2024/06/24/ntpd-rs-deployment.html","score":2,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/4rffe2/more_memory_safety_for_let_s_encrypt","submitter_user":"jmhodges","user_is_author":false,"tags":["networking","rust","security"]},{"short_id":"csl2jn","short_id_url":"https://lobste.rs/s/csl2jn","created_at":"2024-06-24T13:47:59.000-05:00","title":"New sort implementations merged in the Rust standard library - up to 2x faster","url":"https://github.com/rust-lang/rust/pull/124032","score":9,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/csl2jn/new_sort_implementations_merged_rust","submitter_user":"gendx","user_is_author":false,"tags":["performance","rust"]},{"short_id":"kbg55l","short_id_url":"https://lobste.rs/s/kbg55l","created_at":"2024-06-24T13:26:30.000-05:00","title":"Abusing title reporting and tmux integration in iTerm2 for code execution","url":"https://vin01.github.io/piptagole/escape-sequences/iterm2/rce/2024/06/16/iterm2-rce-window-title-tmux-integration.html","score":2,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/kbg55l/abusing_title_reporting_tmux","submitter_user":"fanf","user_is_author":false,"tags":["mac","security"]},{"short_id":"ewwqwr","short_id_url":"https://lobste.rs/s/ewwqwr","created_at":"2024-06-24T13:06:57.000-05:00","title":"sched_ext: scheduler architecture and interfaces (Part 2)","url":"https://blogs.igalia.com/changwoo/sched-ext-scheduler-architecture-and-interfaces-part-2/","score":1,"flags":0,"comment_count":1,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/ewwqwr/sched_ext_scheduler_architecture","submitter_user":"eBPF","user_is_author":false,"tags":["linux"]},{"short_id":"zoopbv","short_id_url":"https://lobste.rs/s/zoopbv","created_at":"2024-06-24T11:41:17.000-05:00","title":"Tag proposal: week and weekend","url":"","score":10,"flags":0,"comment_count":11,"description":"\u003cp\u003eThere are a lot of repeat posts such as “What are people doing this week?” or “What are people doing this weekend?”. When I see them on Twitter, I can unfollow the person and I won’t see it again. There doesn’t seem to be a tag for these repeat posts.\u003c/p\u003e\n\u003cp\u003eI propose we add a tag for them, so people who enjoy these conversations can easily search for them and for those who don’t, they can easily hide them permanently.\u003c/p\u003e\n\u003cp\u003eThese tags should be applied to \u003ca href=\"https://lobste.rs/search?q=tag%3Aask+weekend\u0026amp;what=stories\u0026amp;order=newest\" rel=\"ugc\"\u003eold\u003c/a\u003e \u003ca href=\"https://lobste.rs/search?q=tag%3Aask+week\u0026amp;what=stories\u0026amp;order=newest\" rel=\"ugc\"\u003eposts\u003c/a\u003e retroactively.\u003c/p\u003e\n","description_plain":"There are a lot of repeat posts such as \"What are people doing this week?\" or \"What are people doing this weekend?\". When I see them on Twitter, I can unfollow the person and I won't see it again. There doesn't seem to be a tag for these repeat posts.\r\n\r\nI propose we add a tag for them, so people who enjoy these conversations can easily search for them and for those who don't, they can easily hide them permanently.\r\n\r\nThese tags should be applied to [old](https://lobste.rs/search?q=tag%3Aask+weekend\u0026what=stories\u0026order=newest) [posts](https://lobste.rs/search?q=tag%3Aask+week\u0026what=stories\u0026order=newest) retroactively.","comments_url":"https://lobste.rs/s/zoopbv/tag_proposal_week_weekend","submitter_user":"wyuenho","user_is_author":true,"tags":["meta"]},{"short_id":"w9toij","short_id_url":"https://lobste.rs/s/w9toij","created_at":"2024-06-24T09:49:35.000-05:00","title":"Local, first, forever - CRDT filesync","url":"https://tonsky.me/blog/crdt-filesync/","score":11,"flags":0,"comment_count":4,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/w9toij/local_first_forever_crdt_filesync","submitter_user":"facundoolano","user_is_author":false,"tags":["distributed"]},{"short_id":"7a3qhh","short_id_url":"https://lobste.rs/s/7a3qhh","created_at":"2024-06-24T09:47:15.000-05:00","title":"How’s your experience so far using LLMs for coding","url":"","score":6,"flags":0,"comment_count":23,"description":"\u003cp\u003eWhat has been your experience using LLMs for coding.\nIn what capacity have you been using LLMs when coding.\u003c/p\u003e\n\u003cp\u003eFor me it has been great tool i have been using chatgpt 4 and it has immensely helped me understanding new concepts , building scripts. and prototyping stuff\u003c/p\u003e\n","description_plain":"What has been your experience using LLMs for coding.\r\nIn what capacity have you been using LLMs when coding.\r\n\r\n\r\nFor me it has been great tool i have been using chatgpt 4 and it has immensely helped me understanding new concepts , building scripts. and prototyping stuff","comments_url":"https://lobste.rs/s/7a3qhh/how_s_your_experience_so_far_using_llms_for","submitter_user":"mraza007","user_is_author":true,"tags":["ai","ask","programming"]},{"short_id":"9twcpx","short_id_url":"https://lobste.rs/s/9twcpx","created_at":"2024-06-24T09:38:12.000-05:00","title":"Why Passkey Implementation is 100x Harder Than You Think – Misconceptions, Pitfalls and Unknown Unknowns","url":"https://www.corbado.com/blog/passkey-implementation-pitfalls-misconceptions-unknowns","score":3,"flags":1,"comment_count":2,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/9twcpx/why_passkey_implementation_is_100x","submitter_user":"kivikakk","user_is_author":false,"tags":["security","web"]},{"short_id":"ju9yby","short_id_url":"https://lobste.rs/s/ju9yby","created_at":"2024-06-24T08:41:45.000-05:00","title":"Microfeatures I Love in Blogs and Personal Websites","url":"https://danilafe.com/blog/blog_microfeatures/","score":39,"flags":0,"comment_count":35,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/ju9yby/microfeatures_i_love_blogs_personal","submitter_user":"freddyb","user_is_author":false,"tags":["web"]},{"short_id":"nozetp","short_id_url":"https://lobste.rs/s/nozetp","created_at":"2024-06-24T08:37:18.000-05:00","title":"What is mixed content?","url":"https://frederikbraun.de/mixed-content.html","score":3,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/nozetp/what_is_mixed_content","submitter_user":"freddyb","user_is_author":true,"tags":["security","web"]},{"short_id":"auy5hm","short_id_url":"https://lobste.rs/s/auy5hm","created_at":"2024-06-24T07:35:50.000-05:00","title":"Life in the FastLanes: Decoding \u003e100 billion integers per second with scalar Rust","url":"http://blog.spiraldb.com/life-in-the-fastlanes/","score":13,"flags":0,"comment_count":1,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/auy5hm/life_fastlanes_decoding_100_billion","submitter_user":"gatesn","user_is_author":true,"tags":["databases","performance","rust"]},{"short_id":"bxihli","short_id_url":"https://lobste.rs/s/bxihli","created_at":"2024-06-24T07:18:23.000-05:00","title":"What are you doing this week?","url":"","score":11,"flags":0,"comment_count":13,"description":"\u003cp\u003eWhat are you doing this week? Feel free to share!\u003c/p\u003e\n\u003cp\u003eKeep in mind it’s OK to do nothing at all, too.\u003c/p\u003e\n","description_plain":"What are you doing this week? Feel free to share!\r\n\r\nKeep in mind it’s OK to do nothing at all, too.","comments_url":"https://lobste.rs/s/bxihli/what_are_you_doing_this_week","submitter_user":"caius","user_is_author":true,"tags":["ask","programming"]},{"short_id":"4g7xju","short_id_url":"https://lobste.rs/s/4g7xju","created_at":"2024-06-24T06:33:00.000-05:00","title":"Investigating an Event Queue Hang: The Code Works Correctly","url":"https://gist.github.com/FeepingCreature/a8099d2bcf850a9c388ed045fa3b5c0e","score":8,"flags":0,"comment_count":1,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/4g7xju/investigating_event_queue_hang_code","submitter_user":"FeepingCreature","user_is_author":true,"tags":["debugging","distributed","historical"]},{"short_id":"hp0llm","short_id_url":"https://lobste.rs/s/hp0llm","created_at":"2024-06-24T06:29:12.000-05:00","title":"The Proxmox Hypervisor, on NixOS","url":"https://github.com/SaumonNet/proxmox-nixos","score":14,"flags":0,"comment_count":5,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/hp0llm/proxmox_hypervisor_on_nixos","submitter_user":"JulienMalka","user_is_author":true,"tags":["nix","virtualization"]},{"short_id":"l28aop","short_id_url":"https://lobste.rs/s/l28aop","created_at":"2024-06-24T06:28:57.000-05:00","title":"Ratatui v0.27.0 (a TUI library for Rust)","url":"https://ratatui.rs/highlights/v027/","score":-3,"flags":6,"comment_count":1,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/l28aop/ratatui_v0_27_0_tui_library_for_rust","submitter_user":"orhun","user_is_author":true,"tags":["release","rust","show"]},{"short_id":"09opve","short_id_url":"https://lobste.rs/s/09opve","created_at":"2024-06-24T06:01:01.000-05:00","title":"Cosmopolitan v3.5.0","url":"https://github.com/jart/cosmopolitan/releases/tag/3.5.0","score":9,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/09opve/cosmopolitan_v3_5_0","submitter_user":"reezer","user_is_author":false,"tags":["c","release"]},{"short_id":"jahu16","short_id_url":"https://lobste.rs/s/jahu16","created_at":"2024-06-24T05:22:49.000-05:00","title":"MIME, RSS, and existential torment","url":"https://xeiaso.net/blog/2024/fixing-rss-mailcap/","score":25,"flags":0,"comment_count":10,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/jahu16/mime_rss_existential_torment","submitter_user":"cadey","user_is_author":true,"tags":["devops","go"]},{"short_id":"h5nira","short_id_url":"https://lobste.rs/s/h5nira","created_at":"2024-06-24T04:28:58.000-05:00","title":"Macros and optimizations: it's just a phase","url":"https://marianoguerra.org/posts/macros-and-optimizations-its-just-a-phase/","score":6,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/h5nira/macros_optimizations_it_s_just_phase","submitter_user":"marianoguerra","user_is_author":true,"tags":["compilers","plt"]},{"short_id":"j2ha8f","short_id_url":"https://lobste.rs/s/j2ha8f","created_at":"2024-06-24T02:53:18.000-05:00","title":"Fixed-point math is better than floating point (sometimes)","url":"https://www.youtube.com/watch?v=i1phJl-0v54\u0026t=4s","score":1,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/j2ha8f/fixed_point_math_is_better_than_floating","submitter_user":"FrancisStokes","user_is_author":true,"tags":["c","math","video"]},{"short_id":"bmvyoc","short_id_url":"https://lobste.rs/s/bmvyoc","created_at":"2024-06-24T01:00:13.000-05:00","title":"KDE5, KDE6, tiling and other rants","url":"https://ludditus.com/2024/06/23/kde5-kde6-tiling-and-other-rants/","score":4,"flags":2,"comment_count":4,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/bmvyoc/kde5_kde6_tiling_other_rants","submitter_user":"raymii","user_is_author":false,"tags":["linux","rant"]},{"short_id":"blwhky","short_id_url":"https://lobste.rs/s/blwhky","created_at":"2024-06-23T19:52:39.000-05:00","title":"qq: jq multi-configuration format tool with interactive REPL","url":"https://github.com/JFryy/qq/","score":3,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/blwhky/qq_jq_multi_configuration_format_tool","submitter_user":"andrewfromx","user_is_author":false,"tags":["go"]},{"short_id":"srrfqt","short_id_url":"https://lobste.rs/s/srrfqt","created_at":"2024-06-23T14:07:47.000-05:00","title":"Secrets of the ChatGPT Linux system","url":"https://incoherency.co.uk/blog/stories/chatgpt-linux.html","score":26,"flags":0,"comment_count":11,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/srrfqt/secrets_chatgpt_linux_system","submitter_user":"friendlysock","user_is_author":false,"tags":["reversing"]},{"short_id":"blxfwn","short_id_url":"https://lobste.rs/s/blxfwn","created_at":"2024-06-23T14:02:03.000-05:00","title":"Scalable MatMul-free Language Modeling","url":"https://arxiv.org/pdf/2406.02528","score":3,"flags":0,"comment_count":0,"description":"\u003cp\u003eMatrix multiplication (MatMul) typically dominates the overall computational cost of large language models (LLMs). This cost only grows as LLMs scale to larger embedding dimensions and context lengths. In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model’s memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs. Our code implementation is available at \u003ca href=\"https://github.com/ridgerchu/matmulfreellm\" rel=\"ugc\"\u003ethis https URL\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2406.02528\" rel=\"ugc\"\u003earXiv\u003c/a\u003e\u003c/p\u003e\n","description_plain":"Matrix multiplication (MatMul) typically dominates the overall computational cost of large language models (LLMs). This cost only grows as LLMs scale to larger embedding dimensions and context lengths. In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model's memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs. Our code implementation is available at [this https URL](https://github.com/ridgerchu/matmulfreellm).\r\n\r\n[arXiv](https://arxiv.org/abs/2406.02528)","comments_url":"https://lobste.rs/s/blxfwn/scalable_matmul_free_language_modeling","submitter_user":"calvin","user_is_author":false,"tags":["ai","compsci","pdf","performance"]},{"short_id":"kzl4qt","short_id_url":"https://lobste.rs/s/kzl4qt","created_at":"2024-06-23T13:50:36.000-05:00","title":"Subdividing + Deforming Arbitrary 3D Meshes","url":"https://cprimozic.net/blog/subdividing-meshes-for-displacement/","score":6,"flags":0,"comment_count":0,"description":"","description_plain":"","comments_url":"https://lobste.rs/s/kzl4qt/subdividing_deforming_arbitrary_3d","submitter_user":"Ameo","user_is_author":true,"tags":["graphics","math"]}]