[{"short_id":"ghsrqv","created_at":"2026-02-25T15:26:55.000-06:00","title":"Text-Based Google Directions","url":"https://gdir.telae.net/","score":1,"flags":0,"comment_count":1,"description":"","description_plain":"","submitter_user":"mxuribe","user_is_author":false,"tags":["design","retrocomputing"],"short_id_url":"https://lobste.rs/s/ghsrqv","comments_url":"https://lobste.rs/s/ghsrqv/text_based_google_directions"},{"short_id":"vtyttw","created_at":"2026-02-25T15:16:34.000-06:00","title":"What interesting (and smaller) conferences are there in 2026?","url":"","score":3,"flags":0,"comment_count":0,"description":"\u003cp\u003eIt'd be nice to hear about interesting ones around the world. Particularly smaller ones e.g. for APL or Gleam.\u003c/p\u003e\n","description_plain":"It'd be nice to hear about interesting ones around the world. Particularly smaller ones e.g. for APL or Gleam.","submitter_user":"veqq","user_is_author":true,"tags":["ask","event"],"short_id_url":"https://lobste.rs/s/vtyttw","comments_url":"https://lobste.rs/s/vtyttw/what_interesting_smaller_conferences"},{"short_id":"j3ke5e","created_at":"2026-02-25T14:47:50.000-06:00","title":"Gleam is boring, so I went to a conference about it","url":"https://builders.perk.com/gleam-is-boring-so-i-went-to-a-conference-about-it-8f08a52c3de3","score":1,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"alper","user_is_author":false,"tags":["gleam"],"short_id_url":"https://lobste.rs/s/j3ke5e","comments_url":"https://lobste.rs/s/j3ke5e/gleam_is_boring_so_i_went_conference_about"},{"short_id":"qerqwv","created_at":"2026-02-25T14:47:38.000-06:00","title":"Devirtualization and Static Polymorphism","url":"https://david.alvarezrosa.com/posts/devirtualization-and-static-polymorphism/","score":3,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"noncrab","user_is_author":false,"tags":["c++"],"short_id_url":"https://lobste.rs/s/qerqwv","comments_url":"https://lobste.rs/s/qerqwv/devirtualization_static_polymorphism"},{"short_id":"to9uvq","created_at":"2026-02-25T14:22:34.000-06:00","title":"Recursive Make Considered Harmful [1998,2006]","url":"https://accu.org/journals/overload/14/71/miller_2004/","score":2,"flags":0,"comment_count":3,"description":"","description_plain":"","submitter_user":"Bernerd","user_is_author":false,"tags":["programming"],"short_id_url":"https://lobste.rs/s/to9uvq","comments_url":"https://lobste.rs/s/to9uvq/recursive_make_considered_harmful_1998"},{"short_id":"sys4eu","created_at":"2026-02-25T14:11:49.000-06:00","title":"Practical Decentralization","url":"https://pfrazee.com/blog/practical-decentralization","score":4,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"NoahTheDuke","user_is_author":false,"tags":["distributed"],"short_id_url":"https://lobste.rs/s/sys4eu","comments_url":"https://lobste.rs/s/sys4eu/practical_decentralization"},{"short_id":"9zdqre","created_at":"2026-02-25T13:50:10.000-06:00","title":"Firefox pwn2own 2025 documentary part 2","url":"https://m.youtube.com/watch?v=uXW_1hepfT4","score":1,"flags":0,"comment_count":1,"description":"","description_plain":"","submitter_user":"freddyb","user_is_author":false,"tags":["security","video"],"short_id_url":"https://lobste.rs/s/9zdqre","comments_url":"https://lobste.rs/s/9zdqre/firefox_pwn2own_2025_documentary_part_2"},{"short_id":"f38mb8","created_at":"2026-02-25T12:50:02.000-06:00","title":"Large-Scale Online Deanonymization with LLMs","url":"https://substack.com/home/post/p-189015749","score":2,"flags":0,"comment_count":3,"description":"","description_plain":"","submitter_user":"lr0","user_is_author":false,"tags":["vibecoding"],"short_id_url":"https://lobste.rs/s/f38mb8","comments_url":"https://lobste.rs/s/f38mb8/large_scale_online_deanonymization_with"},{"short_id":"be27h4","created_at":"2026-02-25T12:49:09.000-06:00","title":"Porting Doom to a 20-year-old VoIP phone","url":"https://0x19.co/post/snom360_doom/","score":7,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"lr0","user_is_author":false,"tags":["hardware","programming"],"short_id_url":"https://lobste.rs/s/be27h4","comments_url":"https://lobste.rs/s/be27h4/porting_doom_20_year_old_voip_phone"},{"short_id":"llboto","created_at":"2026-02-25T12:27:11.000-06:00","title":"Fake Job Interviews Are Installing Backdoors on Developer Machines","url":"https://threatroad.substack.com/p/fake-job-interviews-are-installing","score":12,"flags":0,"comment_count":2,"description":"","description_plain":"","submitter_user":"juliethefoxcoon","user_is_author":false,"tags":["security"],"short_id_url":"https://lobste.rs/s/llboto","comments_url":"https://lobste.rs/s/llboto/fake_job_interviews_are_installing"},{"short_id":"kejenj","created_at":"2026-02-25T12:18:40.000-06:00","title":"Computer History Museum Recovers Rare UNIX History","url":"https://youtu.be/-xlq_MPWNKk","score":3,"flags":0,"comment_count":1,"description":"","description_plain":"","submitter_user":"fanf","user_is_author":false,"tags":["unix","video"],"short_id_url":"https://lobste.rs/s/kejenj","comments_url":"https://lobste.rs/s/kejenj/computer_history_museum_recovers_rare"},{"short_id":"e05irn","created_at":"2026-02-25T11:41:45.000-06:00","title":"Create your PostgreSQL clusters with the builtin C collation","url":"https://www.cybertec-postgresql.com/en/c-collation-best-for-postgresql-clusters/","score":1,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"fanf","user_is_author":false,"tags":["databases"],"short_id_url":"https://lobste.rs/s/e05irn","comments_url":"https://lobste.rs/s/e05irn/create_your_postgresql_clusters_with"},{"short_id":"l4nw7u","created_at":"2026-02-25T11:16:59.000-06:00","title":"Windows 11 Notepad to support markdown","url":"https://blogs.windows.com/windows-insider/2026/01/21/notepad-and-paint-updates-begin-rolling-out-to-windows-insiders/","score":10,"flags":0,"comment_count":11,"description":"","description_plain":"","submitter_user":"andreynering","user_is_author":false,"tags":["editors","windows"],"short_id_url":"https://lobste.rs/s/l4nw7u","comments_url":"https://lobste.rs/s/l4nw7u/windows_11_notepad_support_markdown"},{"short_id":"n54hg3","created_at":"2026-02-25T10:41:12.000-06:00","title":"Software Engineering Has Changed","url":"https://lukesnotebook.substack.com/p/software-engineering-has-changed","score":0,"flags":6,"comment_count":0,"description":"","description_plain":"","submitter_user":"lukewilson","user_is_author":true,"tags":["vibecoding"],"short_id_url":"https://lobste.rs/s/n54hg3","comments_url":"https://lobste.rs/s/n54hg3/software_engineering_has_changed"},{"short_id":"ocjdrt","created_at":"2026-02-25T10:41:09.000-06:00","title":"Dictionary of Algorithms and Data Structures","url":"https://xlinux.nist.gov/dads/","score":7,"flags":0,"comment_count":2,"description":"","description_plain":"","submitter_user":"regulator","user_is_author":false,"tags":["compsci"],"short_id_url":"https://lobste.rs/s/ocjdrt","comments_url":"https://lobste.rs/s/ocjdrt/dictionary_algorithms_data_structures"},{"short_id":"4zhkwb","created_at":"2026-02-25T09:38:30.000-06:00","title":"ANN: Tada 0.4.0 - local (cached) dependencies support","url":"https://github.com/tomekw/tada/releases/tag/v0.4.0","score":-1,"flags":2,"comment_count":1,"description":"","description_plain":"","submitter_user":"tomekw","user_is_author":true,"tags":["programming","release"],"short_id_url":"https://lobste.rs/s/4zhkwb","comments_url":"https://lobste.rs/s/4zhkwb/ann_tada_0_4_0_local_cached_dependencies"},{"short_id":"10nlgf","created_at":"2026-02-25T08:57:10.000-06:00","title":"How AI Will Change the Mobile Ecosystem","url":"https://blog.bensontech.dev/posts/How-ai-will-change-mobile-development/","score":-1,"flags":4,"comment_count":0,"description":"","description_plain":"","submitter_user":"informal","user_is_author":true,"tags":["mobile","vibecoding"],"short_id_url":"https://lobste.rs/s/10nlgf","comments_url":"https://lobste.rs/s/10nlgf/how_ai_will_change_mobile_ecosystem"},{"short_id":"owreaj","created_at":"2026-02-25T08:45:13.000-06:00","title":"The Road Ahead for LocalStack: Upcoming Changes to the Delivery of Our AWS Cloud Emulators (2025)","url":"https://blog.localstack.cloud/the-road-ahead-for-localstack/","score":1,"flags":0,"comment_count":1,"description":"\u003cp\u003eIt was published in 2025 but the change will take effect in March, and will likely impact audiences who didn't see their post or otherwise forgot about it:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWhat is changing?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003eOur current distribution for our AWS emulator, which was packaged both as a free Community image (\u003ccode\u003elocalstack/localstack\u003c/code\u003e) and a commercial Pro image (\u003ccode\u003elocalstack/localstack-pro\u003c/code\u003e) on Docker Hub, will be consolidated into a single image beginning in March 2026. Going forward, LocalStack for AWS will be available via a single image distribution on Docker Hub at \u003ccode\u003elocalstack/localstack\u003c/code\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe new unified distribution will require authentication via an auth token for use. This means that, once the change is published in March, pulling and running \u003ccode\u003elocalstack/localstack:latest\u003c/code\u003e will prompt you for an auth token if you have not already provided one.\u003c/p\u003e\n\u003c/blockquote\u003e\n","description_plain":"It was published in 2025 but the change will take effect in March, and will likely impact audiences who didn't see their post or otherwise forgot about it:\r\n\r\n\u003e What is changing?\r\n\r\n\u003e Our current distribution for our AWS emulator, which was packaged both as a free Community image (`localstack/localstack`) and a commercial Pro image (`localstack/localstack-pro`) on Docker Hub, will be consolidated into a single image beginning in March 2026. Going forward, LocalStack for AWS will be available via a single image distribution on Docker Hub at `localstack/localstack`.\r\n\r\n\u003e The new unified distribution will require authentication via an auth token for use. This means that, once the change is published in March, pulling and running `localstack/localstack:latest` will prompt you for an auth token if you have not already provided one.","submitter_user":"mdaniel","user_is_author":false,"tags":["devops","testing"],"short_id_url":"https://lobste.rs/s/owreaj","comments_url":"https://lobste.rs/s/owreaj/road_ahead_for_localstack_upcoming"},{"short_id":"bwkwba","created_at":"2026-02-25T08:35:23.000-06:00","title":"New accounts on HN 10x more likely to use EM-dashes","url":"https://www.marginalia.nu/weird-ai-crap/hn/","score":60,"flags":4,"comment_count":53,"description":"","description_plain":"","submitter_user":"mccd","user_is_author":false,"tags":["vibecoding"],"short_id_url":"https://lobste.rs/s/bwkwba","comments_url":"https://lobste.rs/s/bwkwba/new_accounts_on_hn_10x_more_likely_use_em"},{"short_id":"shzh0m","created_at":"2026-02-25T08:26:21.000-06:00","title":"Current Large Audio Language Models largely transcribe rather than listen","url":"https://arxiv.org/abs/2510.10444","score":9,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"crmne","user_is_author":false,"tags":["ai"],"short_id_url":"https://lobste.rs/s/shzh0m","comments_url":"https://lobste.rs/s/shzh0m/current_large_audio_language_models"},{"short_id":"8utm05","created_at":"2026-02-25T08:23:13.000-06:00","title":"Tests Are The New Moat","url":"https://saewitz.com/tests-are-the-new-moat","score":12,"flags":2,"comment_count":7,"description":"","description_plain":"","submitter_user":"alper","user_is_author":false,"tags":["practices","vibecoding"],"short_id_url":"https://lobste.rs/s/8utm05","comments_url":"https://lobste.rs/s/8utm05/tests_are_new_moat"},{"short_id":"d4lblv","created_at":"2026-02-25T07:50:34.000-06:00","title":"Language-Oriented Programming with Racket (2019)","url":"https://www.youtube.com/watch?v=z8Pz4bJV3Tk","score":13,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"b--man","user_is_author":false,"tags":["lisp","programming","video"],"short_id_url":"https://lobste.rs/s/d4lblv","comments_url":"https://lobste.rs/s/d4lblv/language_oriented_programming_with"},{"short_id":"qjl5xc","created_at":"2026-02-25T07:07:01.000-06:00","title":"Your system is fine. Your users aren't","url":"https://blog.incrementalforgetting.tech/p/your-system-is-fine-your-users-arent","score":9,"flags":5,"comment_count":7,"description":"","description_plain":"","submitter_user":"dunyakirkali","user_is_author":true,"tags":["practices"],"short_id_url":"https://lobste.rs/s/qjl5xc","comments_url":"https://lobste.rs/s/qjl5xc/your_system_is_fine_your_users_aren_t"},{"short_id":"2sdod9","created_at":"2026-02-25T06:51:55.000-06:00","title":"Building Index-Backed Query Plans in DataFusion","url":"https://pierrezemb.fr/posts/datafusion-index-provider/","score":1,"flags":0,"comment_count":0,"description":"","description_plain":"","submitter_user":"emschwartz","user_is_author":false,"tags":["databases"],"short_id_url":"https://lobste.rs/s/2sdod9","comments_url":"https://lobste.rs/s/2sdod9/building_index_backed_query_plans"},{"short_id":"fcnm2x","created_at":"2026-02-25T04:02:06.000-06:00","title":"Mercury: Ultra-Fast Language Models Based on Diffusion","url":"https://arxiv.org/abs/2506.17298","score":6,"flags":0,"comment_count":0,"description":"\u003cp\u003eMachine learning researchers have been locked in the autoregressive bottleneck for years. A recent paper argues that instead, diffusion models can perform at scale on discrete data. The researchers trained two coding models named Mercury Coder Mini and Small. The Mini model reached a staggering 1109 tokens per second on H100 GPUs, with the Small model achieving 737. These models eclipsed competing efficient state-of-the-art models in throughput by factors of up to ten, while retaining their ability to perform the coding tasks they were trained on. On real world testing and human evaluation platforms such as the Copilot Arena, the Mini model tied for second place in quality with massive models like GPT-4o, having an average latency of only 25 milliseconds. The model matched the performance of established high-speed models such as Claude 3.5 Haiku and Gemini 2.0 Flash Lite across a variety of programming languages, but with many orders of magnitude improvement in decode speed.\u003c/p\u003e\n\u003cp\u003eDiffusion models have a clear advantage over older autoregressive ones in their ability to generate text in parallel, which makes things much more efficient. Standard language models are hamstrung by a serial decoding process in which answers have to be produced one piece at a time. Transformer models abandon that bottleneck entirely. They learn to predict many pieces of text all at once. You start with a string of random noise and run a denoting process that refines all the tokens in concert, zooming from coarse to fine, until the final text emerges. This ability to generate in parallel achieves much higher arithmetic intensity and makes full use of the computational power of modern GPUs.\u003c/p\u003e\n","description_plain":"Machine learning researchers have been locked in the autoregressive bottleneck for years. A recent paper argues that instead, diffusion models can perform at scale on discrete data. The researchers trained two coding models named Mercury Coder Mini and Small. The Mini model reached a staggering 1109 tokens per second on H100 GPUs, with the Small model achieving 737. These models eclipsed competing efficient state-of-the-art models in throughput by factors of up to ten, while retaining their ability to perform the coding tasks they were trained on. On real world testing and human evaluation platforms such as the Copilot Arena, the Mini model tied for second place in quality with massive models like GPT-4o, having an average latency of only 25 milliseconds. The model matched the performance of established high-speed models such as Claude 3.5 Haiku and Gemini 2.0 Flash Lite across a variety of programming languages, but with many orders of magnitude improvement in decode speed.\r\n\r\nDiffusion models have a clear advantage over older autoregressive ones in their ability to generate text in parallel, which makes things much more efficient. Standard language models are hamstrung by a serial decoding process in which answers have to be produced one piece at a time. Transformer models abandon that bottleneck entirely. They learn to predict many pieces of text all at once. You start with a string of random noise and run a denoting process that refines all the tokens in concert, zooming from coarse to fine, until the final text emerges. This ability to generate in parallel achieves much higher arithmetic intensity and makes full use of the computational power of modern GPUs.","submitter_user":"Yogthos","user_is_author":false,"tags":["ai"],"short_id_url":"https://lobste.rs/s/fcnm2x","comments_url":"https://lobste.rs/s/fcnm2x/mercury_ultra_fast_language_models_based"}]